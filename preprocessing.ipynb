{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08e0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b45d30",
   "metadata": {},
   "source": [
    "First load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c457845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group(file_name, group_label, gender):\n",
    "    # Load .mat files\n",
    "    data = sio.loadmat(os.path.join('EEG', file_name + '.mat'))\n",
    "    # Get only the last column where all the information that we need is\n",
    "    key = list(data.keys())[-1]\n",
    "    group_data = data[key]\n",
    "\n",
    "    rows = []\n",
    "    # Loop through each cell (tasks)\n",
    "    for task_idx in range(group_data.shape[1]):\n",
    "        task_data = group_data[0, task_idx]\n",
    "        n_subjects, n_samples, n_channels = task_data.shape\n",
    "\n",
    "        for subj_idx in range(n_subjects):\n",
    "            # Handle corrupted sample (skip female ADHD subject 7)\n",
    "            if file_name == \"FADHD\" and subj_idx == 6:\n",
    "                continue\n",
    "            \n",
    "            # This will make it easier to know later to which signal we are referring\n",
    "            signal = task_data[subj_idx, :, :]  # [samples x channels]\n",
    "            rows.append({\n",
    "                \"group\": group_label,    # 'Control' or 'ADHD'\n",
    "                \"gender\": gender,        # 'Male' or 'Female'\n",
    "                \"task\": task_idx + 1,    # 1 to 11\n",
    "                \"subject_id\": f\"{file_name}_{subj_idx+1}\",\n",
    "                \"signal\": signal\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Load all four groups\n",
    "fc_df = load_group(\"FC\", group_label=\"Control\", gender=\"Female\")\n",
    "mc_df = load_group(\"MC\", group_label=\"Control\", gender=\"Male\")\n",
    "fadhd_df = load_group(\"FADHD\", group_label=\"ADHD\", gender=\"Female\")\n",
    "madhd_df = load_group(\"MADHD\", group_label=\"ADHD\", gender=\"Male\")\n",
    "\n",
    "# Combine\n",
    "eeg_df = pd.concat([fc_df, mc_df, fadhd_df, madhd_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de0222",
   "metadata": {},
   "source": [
    "# Preprocessing 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58011db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, iirnotch, welch\n",
    "\n",
    "SFREQ = 256\n",
    "LOW, HIGH = 0.5, 45.0\n",
    "LINE = 50.0  # set to 60.0 if you detect 60 Hz line noise\n",
    "\n",
    "def bandpass(signal, low=LOW, high=HIGH, fs=SFREQ, order=4):\n",
    "    # signal: (samples, channels)\n",
    "    b, a = butter(order, [low/(fs/2), high/(fs/2)], btype='band')\n",
    "    return filtfilt(b, a, signal, axis=0)\n",
    "\n",
    "def notch_filter(signal, f0=LINE, Q=30, fs=SFREQ):\n",
    "    # Apply a single-frequency notch\n",
    "    b, a = iirnotch(w0=f0/(fs/2), Q=Q)\n",
    "    return filtfilt(b, a, signal, axis=0)\n",
    "\n",
    "def hampel_1d(x, k=21, t=3.0):\n",
    "    # simple Hampel filter for impulsive spikes\n",
    "    x = x.copy()\n",
    "    med = np.median(x)\n",
    "    MAD = np.median(np.abs(x - med))\n",
    "    if MAD == 0: return x\n",
    "    thresh = t * 1.4826 * MAD\n",
    "    for i in range(k, len(x)-k):\n",
    "        window = x[i-k:i+k+1]\n",
    "        m = np.median(window); mad = np.median(np.abs(window - m))\n",
    "        if mad == 0: \n",
    "            continue\n",
    "        if np.abs(x[i] - m) > t * 1.4826 * mad:\n",
    "            x[i] = m\n",
    "    return x\n",
    "\n",
    "def clean_spikes(signal):\n",
    "    out = signal.copy()\n",
    "    for ch in range(out.shape[1]):\n",
    "        out[:, ch] = hampel_1d(out[:, ch], k=21, t=3.0)\n",
    "    return out\n",
    "\n",
    "def preprocess_signal(raw, do_notch=True):\n",
    "    # raw: (samples, channels)\n",
    "    x = raw - np.mean(raw, axis=0, keepdims=True)         # detrend (DC)\n",
    "    x = bandpass(x)                                       # 0.5–45 Hz\n",
    "    if do_notch:\n",
    "        x = notch_filter(x)                               # 50/60 Hz\n",
    "    x = clean_spikes(x)                                   # optional\n",
    "    return x\n",
    "\n",
    "def make_bipolar(x):\n",
    "    # returns original + derived bipolar channel\n",
    "    # x: (samples, 2)\n",
    "    bipolar = (x[:, [0]] - x[:, [1]])\n",
    "    return np.hstack([x, bipolar])  # shape: (samples, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc409d4",
   "metadata": {},
   "source": [
    "Duration alignment / sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6971d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_first_seconds(signal, seconds=20, fs=SFREQ):\n",
    "    n = min(signal.shape[0], seconds*fs)\n",
    "    return signal[:n]\n",
    "\n",
    "def sliding_windows(signal, win_sec=5, step_sec=2.5, fs=SFREQ):\n",
    "    win = int(win_sec*fs); step = int(step_sec*fs)\n",
    "    starts = np.arange(0, max(1, signal.shape[0]-win+1), step)\n",
    "    return [signal[s:s+win] for s in starts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975302c",
   "metadata": {},
   "source": [
    "Window quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c24b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_ok(win, amp_thresh=200.0, var_min=1e-6):\n",
    "    if np.any(np.abs(win) > amp_thresh): \n",
    "        return False\n",
    "    if np.any(np.var(win, axis=0) < var_min):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def filter_bad_windows(wins):\n",
    "    good = [w for w in wins if window_ok(w)]\n",
    "    return good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2dc7ca",
   "metadata": {},
   "source": [
    "End-to-end on your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753edf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose strategy\n",
    "USE_SLIDING = True\n",
    "\n",
    "def preprocess_row(row):\n",
    "    sig = row[\"signal\"]\n",
    "    sig = preprocess_signal(sig, do_notch=True)\n",
    "    # optional derived bipolar\n",
    "    sig3 = make_bipolar(sig)  # (N,3) -> ch0, ch1, bipolar\n",
    "    if USE_SLIDING:\n",
    "        wins = sliding_windows(sig3, win_sec=5, step_sec=2.5)\n",
    "        wins = filter_bad_windows(wins)\n",
    "        return wins   # list of windows\n",
    "    else:\n",
    "        fx = fixed_first_seconds(sig3, seconds=20)\n",
    "        return [fx] if window_ok(fx) else []\n",
    "\n",
    "eeg_df[\"windows\"] = eeg_df.apply(preprocess_row, axis=1)\n",
    "# explode to one row per window if you want:\n",
    "exploded = eeg_df.explode(\"windows\").dropna(subset=[\"windows\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391513aa",
   "metadata": {},
   "source": [
    "Standardization without leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710eadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# Build X as features from windows; to standardize raw samples, flatten first\n",
    "# but typically you’ll standardize features after extraction.\n",
    "# Here’s how you’d do it for features later:\n",
    "\n",
    "# Example groups = subject_id to ensure subject-wise CV\n",
    "groups = exploded[\"subject_id\"].values\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for train_idx, test_idx in gkf.split(exploded, exploded[\"group\"], groups):\n",
    "    train_df = exploded.iloc[train_idx]\n",
    "    test_df  = exploded.iloc[test_idx]\n",
    "    # ... extract features from train_df[\"windows\"], fit scaler on train features,\n",
    "    # transform both train and test features, then train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1250b",
   "metadata": {},
   "source": [
    "Parameter tips (sane defaults)\n",
    "\n",
    "- Band-pass: 0.5–45 Hz (order 4–6 Butterworth); if you care about gamma, extend to ~70 Hz and be stricter about EMG.\n",
    "- Notch: 50 Hz or 60 Hz; inspect PSD (welch) to choose. If you see harmonics, notch them too.\n",
    "- Spike threshold: ±150–200 µV is a common heuristic for adult scalp EEG.\n",
    "- Windows: 5 s with 50% overlap is a good trade-off (enough cycles in alpha/theta for stable PSD and entropy).\n",
    "- Downsample: to 128 Hz after filtering if performance matters; adjust band edges accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ee143",
   "metadata": {},
   "source": [
    "# Preprocessing 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e06314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "\n",
    "SFREQ = 256\n",
    "BP_LOW, BP_HIGH = 1.0, 40.0\n",
    "LINE = 50.0\n",
    "\n",
    "def bandpass_simple(x, low=BP_LOW, high=BP_HIGH, fs=SFREQ, order=4):\n",
    "    b, a = butter(order, [low/(fs/2), high/(fs/2)], btype='band')\n",
    "    return filtfilt(b, a, x, axis=0)\n",
    "\n",
    "def notch_simple(x, f0=LINE, Q=30, fs=SFREQ, use_notch=False):\n",
    "    if not use_notch:\n",
    "        return x\n",
    "    b, a = iirnotch(f0/(fs/2), Q)\n",
    "    return filtfilt(b, a, x, axis=0)\n",
    "\n",
    "def first_n_seconds(x, seconds=20, fs=SFREQ):\n",
    "    n = min(x.shape[0], int(seconds*fs))\n",
    "    return x[:n]\n",
    "\n",
    "def artifact_ok(x, amp_thresh=200.0, var_min=1e-8):\n",
    "    if np.any(np.abs(x) > amp_thresh):\n",
    "        return False\n",
    "    if np.any(np.var(x, axis=0) < var_min):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def preprocess_minimal(raw, use_notch=False):\n",
    "    # raw: (samples, 2)\n",
    "    x = raw - np.mean(raw, axis=0, keepdims=True)      # detrend\n",
    "    x = bandpass_simple(x)                             # 1–40 Hz\n",
    "    x = notch_simple(x, use_notch=use_notch)           # optional 50 Hz\n",
    "    x = first_n_seconds(x, seconds=20)                 # align duration\n",
    "    return x if artifact_ok(x) else None               # reject if bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee3eaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 835/869 recordings (96.1%).\n"
     ]
    }
   ],
   "source": [
    "eeg_df[\"clean20s\"] = eeg_df[\"signal\"].apply(lambda s: preprocess_minimal(s, use_notch=False))\n",
    "clean_df = eeg_df.dropna(subset=[\"clean20s\"]).reset_index(drop=True)\n",
    "\n",
    "# Quick QC: how many recordings survived\n",
    "n_all = len(eeg_df)\n",
    "n_ok = len(clean_df)\n",
    "print(f\"Kept {n_ok}/{n_all} recordings ({100*n_ok/n_all:.1f}%).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
